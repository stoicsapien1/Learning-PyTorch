{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661afcf7",
   "metadata": {},
   "source": [
    "YT : https://www.youtube.com/watch?v=MKxEbbKpL5Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b01586a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.3.2-cp310-cp310-win_amd64.whl.metadata (19 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in d:\\learning\\pytorch\\.venv\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\learning\\pytorch\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting scipy>=1.8.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in d:\\learning\\pytorch\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.3.2-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "   ---------------------------------------- 0.0/11.3 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.9/11.3 MB 19.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.6/11.3 MB 18.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.3/11.3 MB 18.2 MB/s  0:00:00\n",
      "Downloading scikit_learn-1.7.2-cp310-cp310-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 3.4/8.9 MB 22.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.9/8.9 MB 19.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 18.4 MB/s  0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading scipy-1.15.3-cp310-cp310-win_amd64.whl (41.3 MB)\n",
      "   ---------------------------------------- 0.0/41.3 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.9/41.3 MB 19.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 7.6/41.3 MB 18.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 11.3/41.3 MB 18.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 14.9/41.3 MB 18.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 18.6/41.3 MB 18.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 22.5/41.3 MB 18.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 25.7/41.3 MB 17.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 28.8/41.3 MB 17.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 32.5/41.3 MB 17.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.4/41.3 MB 17.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 40.1/41.3 MB 17.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 41.3/41.3 MB 16.8 MB/s  0:00:02\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, threadpoolctl, scipy, joblib, scikit-learn, pandas\n",
      "\n",
      "   ---------------------------------------- 0/7 [pytz]\n",
      "   ---------------------------------------- 0/7 [pytz]\n",
      "   ---------------------------------------- 0/7 [pytz]\n",
      "   ----- ---------------------------------- 1/7 [tzdata]\n",
      "   ----- ---------------------------------- 1/7 [tzdata]\n",
      "   ----- ---------------------------------- 1/7 [tzdata]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ----------------- ---------------------- 3/7 [scipy]\n",
      "   ---------------------- ----------------- 4/7 [joblib]\n",
      "   ---------------------- ----------------- 4/7 [joblib]\n",
      "   ---------------------- ----------------- 4/7 [joblib]\n",
      "   ---------------------- ----------------- 4/7 [joblib]\n",
      "   ---------------------- ----------------- 4/7 [joblib]\n",
      "   ---------------------- ----------------- 4/7 [joblib]\n",
      "   ---------------------- ----------------- 4/7 [joblib]\n",
      "   ---------------------- ----------------- 4/7 [joblib]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------- ----------- 5/7 [scikit-learn]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------- ----- 6/7 [pandas]\n",
      "   ---------------------------------------- 7/7 [pandas]\n",
      "\n",
      "Successfully installed joblib-1.5.2 pandas-2.3.2 pytz-2025.2 scikit-learn-1.7.2 scipy-1.15.3 threadpoolctl-3.6.0 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6461f228",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaee9a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfbf4e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdc2a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['id', 'Unnamed: 32'], inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23474e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0           M        17.99         10.38          122.80     1001.0   \n",
       "1           M        20.57         17.77          132.90     1326.0   \n",
       "2           M        19.69         21.25          130.00     1203.0   \n",
       "3           M        11.42         20.38           77.58      386.1   \n",
       "4           M        20.29         14.34          135.10     1297.0   \n",
       "..        ...          ...           ...             ...        ...   \n",
       "564         M        21.56         22.39          142.00     1479.0   \n",
       "565         M        20.13         28.25          131.20     1261.0   \n",
       "566         M        16.60         28.08          108.30      858.1   \n",
       "567         M        20.60         29.33          140.10     1265.0   \n",
       "568         B         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47dbed3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 1:], df.iloc[:, 0], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4f8e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc3b992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.60107448, -1.01785409, -0.59144536, ..., -1.01933729,\n",
       "         0.34322698, -0.46791701],\n",
       "       [ 1.03542061,  0.32300681,  1.07451042, ...,  0.56290508,\n",
       "        -0.73816201, -0.38805344],\n",
       "       [-0.22122483,  0.2162947 , -0.17298646, ...,  0.52785926,\n",
       "         1.34936046,  0.97826109],\n",
       "       ...,\n",
       "       [-0.74958712, -0.47269438, -0.73950267, ..., -0.77005488,\n",
       "        -0.54020729, -0.19486995],\n",
       "       [-0.0984163 , -0.15487787, -0.11451005, ...,  0.2109232 ,\n",
       "        -0.1066701 ,  0.30967353],\n",
       "       [-0.33546533, -0.26158998, -0.29201293, ..., -0.07553825,\n",
       "        -0.54347927,  0.23520615]], shape=(455, 30))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba450853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "349    B\n",
       "156    M\n",
       "43     M\n",
       "134    M\n",
       "372    M\n",
       "      ..\n",
       "385    M\n",
       "438    B\n",
       "142    B\n",
       "523    B\n",
       "518    B\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dc4af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd6c0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train= encoder.fit_transform(y_train)\n",
    "\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38fdde79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d6d731d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66c6a57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "y_test_tensor = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22ce7d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([114, 30])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "870c0ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "        0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0,\n",
       "        1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "        0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1464dc",
   "metadata": {},
   "source": [
    "# Defining Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4edb181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySimpleNN():\n",
    "\n",
    "    def __init__(self,X):\n",
    "\n",
    "        self.weights = torch.rand(X.shape[1],1,dtype = torch.float64,requires_grad=True)\n",
    "        self.bias = torch.zeros(1,dtype=torch.float64,requires_grad=True)\n",
    "    \n",
    "    def forward(self,X):\n",
    "\n",
    "        z = torch.matmul(X,self.weights) + self.bias # wTx+b\n",
    "\n",
    "        y_pred = torch.sigmoid(z)\n",
    "\n",
    "        return y_pred\n",
    "        \n",
    "    def loss_function(self, y_pred, y):\n",
    "        # Clamp predictions to avoid log(0)\n",
    "        epsilon = 1e-7\n",
    "        y_pred = torch.clamp(y_pred, epsilon, 1 - epsilon)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = -(y_train_tensor * torch.log(y_pred) + (1 - y_train_tensor) * torch.log(1 - y_pred)).mean()\n",
    "        return loss\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "705cd182",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =0.1\n",
    "\n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1defc5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6898],\n",
       "        [0.7703],\n",
       "        [0.8524],\n",
       "        [0.3776],\n",
       "        [0.7076],\n",
       "        [0.6708],\n",
       "        [0.5776],\n",
       "        [0.8135],\n",
       "        [0.1720],\n",
       "        [0.7749],\n",
       "        [0.4146],\n",
       "        [0.3933],\n",
       "        [0.7956],\n",
       "        [0.3998],\n",
       "        [0.8155],\n",
       "        [0.4616],\n",
       "        [0.2208],\n",
       "        [0.6596],\n",
       "        [0.9619],\n",
       "        [0.3098],\n",
       "        [0.6872],\n",
       "        [0.5279],\n",
       "        [0.6785],\n",
       "        [0.8314],\n",
       "        [0.2749],\n",
       "        [0.5775],\n",
       "        [0.7531],\n",
       "        [0.3124],\n",
       "        [0.7794],\n",
       "        [0.3805]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(X_train.shape[1],1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa59fa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =0.125\n",
    "\n",
    "epochs = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ecccabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MySimpleNN(X_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a5cea8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3269],\n",
       "         [0.6271],\n",
       "         [0.4850],\n",
       "         [0.2025],\n",
       "         [0.5025],\n",
       "         [0.2837],\n",
       "         [0.2860],\n",
       "         [0.7533],\n",
       "         [0.5859],\n",
       "         [0.3032],\n",
       "         [0.7474],\n",
       "         [0.0019],\n",
       "         [0.6155],\n",
       "         [0.4673],\n",
       "         [0.1768],\n",
       "         [0.3494],\n",
       "         [0.5983],\n",
       "         [0.3840],\n",
       "         [0.4991],\n",
       "         [0.0191],\n",
       "         [0.5695],\n",
       "         [0.6038],\n",
       "         [0.5695],\n",
       "         [0.0030],\n",
       "         [0.1160],\n",
       "         [0.3097],\n",
       "         [0.9567],\n",
       "         [0.3863],\n",
       "         [0.8194],\n",
       "         [0.3504]], dtype=torch.float64, requires_grad=True),\n",
       " tensor([0.], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights,model.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17bd2e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1,Loss : 3.9776027270809093\n",
      "Epoch:2,Loss : 3.834475348839349\n",
      "Epoch:3,Loss : 3.6767136004390397\n",
      "Epoch:4,Loss : 3.5078453498798594\n",
      "Epoch:5,Loss : 3.335071921417582\n",
      "Epoch:6,Loss : 3.1610868779052423\n",
      "Epoch:7,Loss : 2.982871194485778\n",
      "Epoch:8,Loss : 2.803597117060661\n",
      "Epoch:9,Loss : 2.6136705769963133\n",
      "Epoch:10,Loss : 2.416422579054897\n",
      "Epoch:11,Loss : 2.2197481809634385\n",
      "Epoch:12,Loss : 2.0198777618039405\n",
      "Epoch:13,Loss : 1.8157967750846984\n",
      "Epoch:14,Loss : 1.6256220715813134\n",
      "Epoch:15,Loss : 1.4508182845004158\n",
      "Epoch:16,Loss : 1.2925548112455743\n",
      "Epoch:17,Loss : 1.1583409780920693\n",
      "Epoch:18,Loss : 1.0503837742129667\n",
      "Epoch:19,Loss : 0.9685029731932822\n",
      "Epoch:20,Loss : 0.9095578164319562\n",
      "Epoch:21,Loss : 0.8683703388105112\n",
      "Epoch:22,Loss : 0.8393963374645235\n",
      "Epoch:23,Loss : 0.8181713023954538\n",
      "Epoch:24,Loss : 0.8017671102137286\n",
      "Epoch:25,Loss : 0.7884555092089539\n",
      "Epoch:26,Loss : 0.7772468335480623\n",
      "Epoch:27,Loss : 0.7675653356663902\n",
      "Epoch:28,Loss : 0.7590605403776709\n",
      "Epoch:29,Loss : 0.7515053055331962\n",
      "Epoch:30,Loss : 0.7447421085926269\n",
      "Epoch:31,Loss : 0.7386547416053242\n",
      "Epoch:32,Loss : 0.7331531054328742\n",
      "Epoch:33,Loss : 0.7281647284432233\n",
      "Epoch:34,Loss : 0.7236297734538321\n",
      "Epoch:35,Loss : 0.7194979035435479\n",
      "Epoch:36,Loss : 0.7157261838157237\n",
      "Epoch:37,Loss : 0.7122775961006953\n",
      "Epoch:38,Loss : 0.7091199412758539\n",
      "Epoch:39,Loss : 0.7062250025443582\n",
      "Epoch:40,Loss : 0.703567893578202\n",
      "Epoch:41,Loss : 0.701126542571085\n",
      "Epoch:42,Loss : 0.6988812787690274\n",
      "Epoch:43,Loss : 0.696814497587279\n",
      "Epoch:44,Loss : 0.6949103866998064\n",
      "Epoch:45,Loss : 0.6931546998529815\n",
      "Epoch:46,Loss : 0.6915345683128234\n",
      "Epoch:47,Loss : 0.6900383421989884\n",
      "Epoch:48,Loss : 0.6886554557261522\n",
      "Epoch:49,Loss : 0.6873763117186742\n",
      "Epoch:50,Loss : 0.6861921817937503\n",
      "Epoch:51,Loss : 0.6850951193981311\n",
      "Epoch:52,Loss : 0.6840778834905924\n",
      "Epoch:53,Loss : 0.6831338711294742\n",
      "Epoch:54,Loss : 0.6822570575843093\n",
      "Epoch:55,Loss : 0.6814419428678997\n",
      "Epoch:56,Loss : 0.680683503799343\n",
      "Epoch:57,Loss : 0.6799771508742887\n",
      "Epoch:58,Loss : 0.6793186893474645\n",
      "Epoch:59,Loss : 0.6787042840329826\n",
      "Epoch:60,Loss : 0.6781304274068126\n",
      "Epoch:61,Loss : 0.6775939106581838\n",
      "Epoch:62,Loss : 0.6770917973864421\n",
      "Epoch:63,Loss : 0.6766213996800174\n",
      "Epoch:64,Loss : 0.676180256346863\n",
      "Epoch:65,Loss : 0.6757661130927428\n",
      "Epoch:66,Loss : 0.6753769044663243\n",
      "Epoch:67,Loss : 0.6750107374091484\n",
      "Epoch:68,Loss : 0.6746658762649663\n",
      "Epoch:69,Loss : 0.6743407291171317\n",
      "Epoch:70,Loss : 0.6740338353352243\n",
      "Epoch:71,Loss : 0.673743854223092\n",
      "Epoch:72,Loss : 0.6734695546703332\n",
      "Epoch:73,Loss : 0.6732098057180602\n",
      "Epoch:74,Loss : 0.6729635679577289\n",
      "Epoch:75,Loss : 0.672729885689024\n",
      "Epoch:76,Loss : 0.6725078797693275\n",
      "Epoch:77,Loss : 0.6722967410932462\n",
      "Epoch:78,Loss : 0.672095724646102\n",
      "Epoch:79,Loss : 0.671904144080241\n",
      "Epoch:80,Loss : 0.6717213667675397\n",
      "Epoch:81,Loss : 0.6715468092856158\n",
      "Epoch:82,Loss : 0.6713799332990296\n",
      "Epoch:83,Loss : 0.6712202418002022\n",
      "Epoch:84,Loss : 0.6710672756779343\n",
      "Epoch:85,Loss : 0.6709206105842722\n",
      "Epoch:86,Loss : 0.6707798540731014\n",
      "Epoch:87,Loss : 0.6706446429862275\n",
      "Epoch:88,Loss : 0.6705146410648986\n",
      "Epoch:89,Loss : 0.6703895367666972\n",
      "Epoch:90,Loss : 0.6702690412695493\n",
      "Epoch:91,Loss : 0.6701528866462423\n",
      "Epoch:92,Loss : 0.6700408241943451\n",
      "Epoch:93,Loss : 0.6699326229077875\n",
      "Epoch:94,Loss : 0.6698280680775992\n",
      "Epoch:95,Loss : 0.6697269600104373\n",
      "Epoch:96,Loss : 0.6696291128545577\n",
      "Epoch:97,Loss : 0.6695343535238202\n",
      "Epoch:98,Loss : 0.6694425207111622\n",
      "Epoch:99,Loss : 0.6693534639837525\n",
      "Epoch:100,Loss : 0.6692670429527285\n",
      "Epoch:101,Loss : 0.6691831265110683\n",
      "Epoch:102,Loss : 0.6691015921337117\n",
      "Epoch:103,Loss : 0.6690223252345889\n",
      "Epoch:104,Loss : 0.668945218575673\n",
      "Epoch:105,Loss : 0.6688701717236221\n",
      "Epoch:106,Loss : 0.6687970905499616\n",
      "Epoch:107,Loss : 0.6687258867711202\n",
      "Epoch:108,Loss : 0.6686564775249559\n",
      "Epoch:109,Loss : 0.668588784980707\n",
      "Epoch:110,Loss : 0.6685227359795681\n",
      "Epoch:111,Loss : 0.668458261703344\n",
      "Epoch:112,Loss : 0.6683952973688436\n",
      "Epoch:113,Loss : 0.6683337819458947\n",
      "Epoch:114,Loss : 0.6682736578970312\n",
      "Epoch:115,Loss : 0.668214870937079\n",
      "Epoch:116,Loss : 0.6681573698110191\n",
      "Epoch:117,Loss : 0.6681011060886418\n",
      "Epoch:118,Loss : 0.6680460339746382\n",
      "Epoch:119,Loss : 0.667992110132886\n",
      "Epoch:120,Loss : 0.6679392935237907\n",
      "Epoch:121,Loss : 0.6678875452536485\n",
      "Epoch:122,Loss : 0.6678368284350717\n",
      "Epoch:123,Loss : 0.6677871080576047\n",
      "Epoch:124,Loss : 0.6677383508677329\n",
      "Epoch:125,Loss : 0.6676905252575497\n",
      "Epoch:126,Loss : 0.6676436011614044\n",
      "Epoch:127,Loss : 0.6675975499599193\n",
      "Epoch:128,Loss : 0.6675523443908042\n",
      "Epoch:129,Loss : 0.6675079584659503\n",
      "Epoch:130,Loss : 0.6674643673943221\n",
      "Epoch:131,Loss : 0.6674215475102107\n",
      "Epoch:132,Loss : 0.667379476206441\n",
      "Epoch:133,Loss : 0.6673381318721636\n",
      "Epoch:134,Loss : 0.6672974938348858\n",
      "Epoch:135,Loss : 0.6672575423064304\n",
      "Epoch:136,Loss : 0.6672182583325291\n",
      "Epoch:137,Loss : 0.6671796237457841\n",
      "Epoch:138,Loss : 0.6671416211217519\n",
      "Epoch:139,Loss : 0.6671042337379226\n",
      "Epoch:140,Loss : 0.6670674455353821\n",
      "Epoch:141,Loss : 0.6670312410829692\n",
      "Epoch:142,Loss : 0.6669956055437429\n",
      "Epoch:143,Loss : 0.666960524643601\n",
      "Epoch:144,Loss : 0.6669259846418932\n",
      "Epoch:145,Loss : 0.6668919723038897\n",
      "Epoch:146,Loss : 0.6668584748749774\n",
      "Epoch:147,Loss : 0.6668254800564578\n",
      "Epoch:148,Loss : 0.6667929759828418\n",
      "Epoch:149,Loss : 0.6667609512005348\n",
      "Epoch:150,Loss : 0.6667293946478147\n",
      "Epoch:151,Loss : 0.6666982956360203\n",
      "Epoch:152,Loss : 0.6666676438318632\n",
      "Epoch:153,Loss : 0.6666374292407882\n",
      "Epoch:154,Loss : 0.6666076421913149\n",
      "Epoch:155,Loss : 0.66657827332029\n",
      "Epoch:156,Loss : 0.6665493135589954\n",
      "Epoch:157,Loss : 0.6665207541200505\n",
      "Epoch:158,Loss : 0.6664925864850613\n",
      "Epoch:159,Loss : 0.666464802392963\n",
      "Epoch:160,Loss : 0.666437393829016\n",
      "Epoch:161,Loss : 0.6664103530144083\n",
      "Epoch:162,Loss : 0.6663836723964308\n",
      "Epoch:163,Loss : 0.6663573446391826\n",
      "Epoch:164,Loss : 0.6663313626147797\n",
      "Epoch:165,Loss : 0.6663057193950293\n",
      "Epoch:166,Loss : 0.6662804082435455\n",
      "Epoch:167,Loss : 0.6662554226082755\n",
      "Epoch:168,Loss : 0.6662307561144131\n",
      "Epoch:169,Loss : 0.6662064025576728\n",
      "Epoch:170,Loss : 0.6661823558979096\n",
      "Epoch:171,Loss : 0.6661586102530521\n",
      "Epoch:172,Loss : 0.6661351598933424\n",
      "Epoch:173,Loss : 0.6661119992358548\n",
      "Epoch:174,Loss : 0.6660891228392833\n",
      "Epoch:175,Loss : 0.6660665253989777\n",
      "Epoch:176,Loss : 0.6660442017422158\n",
      "Epoch:177,Loss : 0.6660221468236982\n",
      "Epoch:178,Loss : 0.6660003557212526\n",
      "Epoch:179,Loss : 0.6659788236317344\n",
      "Epoch:180,Loss : 0.6659575458671138\n",
      "Epoch:181,Loss : 0.6659365178507387\n",
      "Epoch:182,Loss : 0.6659157351137633\n",
      "Epoch:183,Loss : 0.665895193291733\n",
      "Epoch:184,Loss : 0.665874888121318\n",
      "Epoch:185,Loss : 0.6658548154371846\n",
      "Epoch:186,Loss : 0.6658349711690027\n",
      "Epoch:187,Loss : 0.6658153513385738\n",
      "Epoch:188,Loss : 0.6657959520570816\n",
      "Epoch:189,Loss : 0.6657767695224522\n",
      "Epoch:190,Loss : 0.6657578000168214\n",
      "Epoch:191,Loss : 0.6657390399041028\n",
      "Epoch:192,Loss : 0.665720485627653\n",
      "Epoch:193,Loss : 0.6657021337080246\n",
      "Epoch:194,Loss : 0.6656839807408079\n",
      "Epoch:195,Loss : 0.6656660233945533\n",
      "Epoch:196,Loss : 0.6656482584087718\n",
      "Epoch:197,Loss : 0.6656306825920101\n",
      "Epoch:198,Loss : 0.6656132928199943\n",
      "Epoch:199,Loss : 0.6655960860338429\n",
      "Epoch:200,Loss : 0.6655790592383414\n",
      "Epoch:201,Loss : 0.6655622095002798\n",
      "Epoch:202,Loss : 0.665545533946846\n",
      "Epoch:203,Loss : 0.6655290297640761\n",
      "Epoch:204,Loss : 0.6655126941953569\n",
      "Epoch:205,Loss : 0.6654965245399779\n",
      "Epoch:206,Loss : 0.6654805181517325\n",
      "Epoch:207,Loss : 0.6654646724375649\n",
      "Epoch:208,Loss : 0.665448984856261\n",
      "Epoch:209,Loss : 0.6654334529171807\n",
      "Epoch:210,Loss : 0.6654180741790305\n",
      "Epoch:211,Loss : 0.665402846248677\n",
      "Epoch:212,Loss : 0.6653877667799918\n",
      "Epoch:213,Loss : 0.6653728334727393\n",
      "Epoch:214,Loss : 0.6653580440714914\n",
      "Epoch:215,Loss : 0.6653433963645792\n",
      "Epoch:216,Loss : 0.6653288881830736\n",
      "Epoch:217,Loss : 0.6653145173997982\n",
      "Epoch:218,Loss : 0.6653002819283683\n",
      "Epoch:219,Loss : 0.6652861797222589\n",
      "Epoch:220,Loss : 0.6652722087739005\n",
      "Epoch:221,Loss : 0.6652583671137984\n",
      "Epoch:222,Loss : 0.6652446528096779\n",
      "Epoch:223,Loss : 0.6652310639656541\n",
      "Epoch:224,Loss : 0.6652175987214215\n",
      "Epoch:225,Loss : 0.665204255251469\n",
      "Epoch:226,Loss : 0.6651910317643152\n",
      "Epoch:227,Loss : 0.6651779265017628\n",
      "Epoch:228,Loss : 0.6651649377381751\n",
      "Epoch:229,Loss : 0.6651520637797688\n",
      "Epoch:230,Loss : 0.6651393029639288\n",
      "Epoch:231,Loss : 0.6651266536585373\n",
      "Epoch:232,Loss : 0.6651141142613223\n",
      "Epoch:233,Loss : 0.6651016831992227\n",
      "Epoch:234,Loss : 0.6650893589277689\n",
      "Epoch:235,Loss : 0.6650771399304776\n",
      "Epoch:236,Loss : 0.6650650247182655\n",
      "Epoch:237,Loss : 0.6650530118288743\n",
      "Epoch:238,Loss : 0.6650410998263102\n",
      "Epoch:239,Loss : 0.6650292873002995\n",
      "Epoch:240,Loss : 0.6650175728657541\n",
      "Epoch:241,Loss : 0.665005955162253\n",
      "Epoch:242,Loss : 0.6649944328535342\n",
      "Epoch:243,Loss : 0.6649830046269994\n",
      "Epoch:244,Loss : 0.6649716691932309\n",
      "Epoch:245,Loss : 0.6649604252855194\n",
      "Epoch:246,Loss : 0.6649492716594032\n",
      "Epoch:247,Loss : 0.6649382070922178\n",
      "Epoch:248,Loss : 0.6649272303826561\n",
      "Epoch:249,Loss : 0.6649163403503394\n",
      "Epoch:250,Loss : 0.6649055358353972\n"
     ]
    }
   ],
   "source": [
    "model = MySimpleNN(X_train_tensor)\n",
    "\n",
    "# define loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # forward paas\n",
    "\n",
    "    y_pred = model.forward(X_train_tensor)\n",
    "   \n",
    "\n",
    "    # loss calculate\n",
    "    loss = model.loss_function(y_pred,y_test_tensor)\n",
    "    print(f'Epoch:{epoch+1},Loss : {loss.item()}')\n",
    "\n",
    "\n",
    "    # backward pass\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # parameter update\n",
    "    with torch.no_grad():\n",
    "        model.weights-= learning_rate * model.weights.grad\n",
    "\n",
    "        model.bias -=learning_rate * model.bias.grad\n",
    "\n",
    "    # zero gradients\n",
    "\n",
    "    model.weights.grad.zero_()\n",
    "    model.bias.grad.zero_()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3151b578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6354262828826904\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    y_pred = model.forward(X_test_tensor)\n",
    "    y_pred = (y_pred>0.5).float()\n",
    "\n",
    "    accuracy = (y_pred == y_test_tensor).float().mean()\n",
    "    print(f'Accuracy: {accuracy.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e4f036d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14996678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
